# Athlete_ETL
Created an efficient ETL pipeline that extracted Olympic athletes' data from HDFS, cleaned and transformed it using Spark, and efficiently stored the data in Hive. This pipeline enabled the seamless processing of 120 years of data. I also performed complex queries, aggregations, and joins within Hive to generate detailed analyses and actionable insights. Additionally, the project involved optimizing data storage and query performance to handle large-scale datasets effectively.







